{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "승객의 나이, 성별, 승객 등급, 승선 위치 같은 속서을 기반으로 하여 승객의 생존 여부를 예측하는 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DownLoading train.csv\n",
      "DownLoading test.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "\n",
    "TITANIC_PATH = os.path.join(\"datasets\", \"titanic\")\n",
    "DOWNLOAD_URL = \"https://raw.githubusercontent.com/rickiepark/handson-ml2/master/datasets/titanic/\"\n",
    "\n",
    "if not os.path.isdir(TITANIC_PATH):\n",
    "    os.makedirs(TITANIC_PATH, exist_ok=True)\n",
    "\n",
    "for filename in (\"train.csv\", \"test.csv\"):\n",
    "    filepath = os.path.join(TITANIC_PATH, filename)\n",
    "    print(\"DownLoading\", filename)\n",
    "    urllib.request.urlretrieve(DOWNLOAD_URL + filename,filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_data  = pd.read_csv(TITANIC_PATH +\"/train.csv\")\n",
    "test_data = pd.read_csv(TITANIC_PATH+ \"/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터가 잘 저장 되어 있는지 확인하는 과정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Survived  Pclass  \\\n",
       "PassengerId                     \n",
       "1                   0       3   \n",
       "2                   1       1   \n",
       "3                   1       3   \n",
       "4                   1       1   \n",
       "5                   0       3   \n",
       "\n",
       "                                                          Name     Sex   Age  \\\n",
       "PassengerId                                                                    \n",
       "1                                      Braund, Mr. Owen Harris    male  22.0   \n",
       "2            Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0   \n",
       "3                                       Heikkinen, Miss. Laina  female  26.0   \n",
       "4                 Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0   \n",
       "5                                     Allen, Mr. William Henry    male  35.0   \n",
       "\n",
       "             SibSp  Parch            Ticket     Fare Cabin Embarked  \n",
       "PassengerId                                                          \n",
       "1                1      0         A/5 21171   7.2500   NaN        S  \n",
       "2                1      0          PC 17599  71.2833   C85        C  \n",
       "3                0      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "4                1      0            113803  53.1000  C123        S  \n",
       "5                0      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.info()\n",
    "train_data.set_index('PassengerId', inplace= True)\n",
    "test_data.set_index('PassengerId', inplace= True)\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 418 entries, 892 to 1309\n",
      "Data columns (total 10 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   Pclass    418 non-null    int64  \n",
      " 1   Name      418 non-null    object \n",
      " 2   Sex       418 non-null    object \n",
      " 3   Age       332 non-null    float64\n",
      " 4   SibSp     418 non-null    int64  \n",
      " 5   Parch     418 non-null    int64  \n",
      " 6   Ticket    418 non-null    object \n",
      " 7   Fare      417 non-null    float64\n",
      " 8   Cabin     91 non-null     object \n",
      " 9   Embarked  418 non-null    object \n",
      "dtypes: float64(2), int64(3), object(5)\n",
      "memory usage: 35.9+ KB\n"
     ]
    }
   ],
   "source": [
    "test_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>20.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Survived      Pclass         Age       SibSp       Parch        Fare\n",
       "count  891.000000  891.000000  714.000000  891.000000  891.000000  891.000000\n",
       "mean     0.383838    2.308642   29.699118    0.523008    0.381594   32.204208\n",
       "std      0.486592    0.836071   14.526497    1.102743    0.806057   49.693429\n",
       "min      0.000000    1.000000    0.420000    0.000000    0.000000    0.000000\n",
       "25%      0.000000    2.000000   20.125000    0.000000    0.000000    7.910400\n",
       "50%      0.000000    3.000000   28.000000    0.000000    0.000000   14.454200\n",
       "75%      1.000000    3.000000   38.000000    1.000000    0.000000   31.000000\n",
       "max      1.000000    3.000000   80.000000    8.000000    6.000000  512.329200"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3    491\n",
      "1    216\n",
      "2    184\n",
      "Name: Pclass, dtype: int64, male      577\n",
      "female    314\n",
      "Name: Sex, dtype: int64, B96 B98        4\n",
      "G6             4\n",
      "C23 C25 C27    4\n",
      "C22 C26        3\n",
      "F33            3\n",
      "              ..\n",
      "E34            1\n",
      "C7             1\n",
      "C54            1\n",
      "E36            1\n",
      "C148           1\n",
      "Name: Cabin, Length: 147, dtype: int64, S    644\n",
      "C    168\n",
      "Q     77\n",
      "Name: Embarked, dtype: int64]\n"
     ]
    }
   ],
   "source": [
    "train_data[\"Survived\"].value_counts()\n",
    "print([train_data[i].value_counts() for i in [\"Pclass\",\"Sex\",\"Cabin\",\"Embarked\"]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29.69911764705882\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "mean_age=np.mean(train_data[\"Age\"])\n",
    "print(f\"{mean_age}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 891 entries, 1 to 891\n",
      "Data columns (total 11 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   Survived  891 non-null    int64  \n",
      " 1   Pclass    891 non-null    int64  \n",
      " 2   Name      891 non-null    object \n",
      " 3   Sex       891 non-null    object \n",
      " 4   Age       891 non-null    float64\n",
      " 5   SibSp     891 non-null    int64  \n",
      " 6   Parch     891 non-null    int64  \n",
      " 7   Ticket    891 non-null    object \n",
      " 8   Fare      891 non-null    float64\n",
      " 9   Cabin     204 non-null    object \n",
      " 10  Embarked  889 non-null    object \n",
      "dtypes: float64(2), int64(4), object(5)\n",
      "memory usage: 83.5+ KB\n"
     ]
    }
   ],
   "source": [
    "train_data[\"Age\"].fillna(mean_age, inplace=True)\n",
    "train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[22.         38.         26.         35.         35.         29.69911765\n 54.          2.         27.         14.          4.         58.\n 20.         39.         14.         55.          2.         29.69911765\n 31.         29.69911765 35.         34.         15.         28.\n  8.         38.         29.69911765 19.         29.69911765 29.69911765\n 40.         29.69911765 29.69911765 66.         28.         42.\n 29.69911765 21.         18.         14.         40.         27.\n 29.69911765  3.         19.         29.69911765 29.69911765 29.69911765\n 29.69911765 18.          7.         21.         49.         29.\n 65.         29.69911765 21.         28.5         5.         11.\n 22.         38.         45.          4.         29.69911765 29.69911765\n 29.         19.         17.         26.         32.         16.\n 21.         26.         32.         25.         29.69911765 29.69911765\n  0.83       30.         22.         29.         29.69911765 28.\n 17.         33.         16.         29.69911765 23.         24.\n 29.         20.         46.         26.         59.         29.69911765\n 71.         23.         34.         34.         28.         29.69911765\n 21.         33.         37.         28.         21.         29.69911765\n 38.         29.69911765 47.         14.5        22.         20.\n 17.         21.         70.5        29.         24.          2.\n 21.         29.69911765 32.5        32.5        54.         12.\n 29.69911765 24.         29.69911765 45.         33.         20.\n 47.         29.         25.         23.         19.         37.\n 16.         24.         29.69911765 22.         24.         19.\n 18.         19.         27.          9.         36.5        42.\n 51.         22.         55.5        40.5        29.69911765 51.\n 16.         30.         29.69911765 29.69911765 44.         40.\n 26.         17.          1.          9.         29.69911765 45.\n 29.69911765 28.         61.          4.          1.         21.\n 56.         18.         29.69911765 50.         30.         36.\n 29.69911765 29.69911765  9.          1.          4.         29.69911765\n 29.69911765 45.         40.         36.         32.         19.\n 19.          3.         44.         58.         29.69911765 42.\n 29.69911765 24.         28.         29.69911765 34.         45.5\n 18.          2.         32.         26.         16.         40.\n 24.         35.         22.         30.         29.69911765 31.\n 27.         42.         32.         30.         16.         27.\n 51.         29.69911765 38.         22.         19.         20.5\n 18.         29.69911765 35.         29.         59.          5.\n 24.         29.69911765 44.          8.         19.         33.\n 29.69911765 29.69911765 29.         22.         30.         44.\n 25.         24.         37.         54.         29.69911765 29.\n 62.         30.         41.         29.         29.69911765 30.\n 35.         50.         29.69911765  3.         52.         40.\n 29.69911765 36.         16.         25.         58.         35.\n 29.69911765 25.         41.         37.         29.69911765 63.\n 45.         29.69911765  7.         35.         65.         28.\n 16.         19.         29.69911765 33.         30.         22.\n 42.         22.         26.         19.         36.         24.\n 24.         29.69911765 23.5         2.         29.69911765 50.\n 29.69911765 29.69911765 19.         29.69911765 29.69911765  0.92\n 29.69911765 17.         30.         30.         24.         18.\n 26.         28.         43.         26.         24.         54.\n 31.         40.         22.         27.         30.         22.\n 29.69911765 36.         61.         36.         31.         16.\n 29.69911765 45.5        38.         16.         29.69911765 29.69911765\n 29.         41.         45.         45.          2.         24.\n 28.         25.         36.         24.         40.         29.69911765\n  3.         42.         23.         29.69911765 15.         25.\n 29.69911765 28.         22.         38.         29.69911765 29.69911765\n 40.         29.         45.         35.         29.69911765 30.\n 60.         29.69911765 29.69911765 24.         25.         18.\n 19.         22.          3.         29.69911765 22.         27.\n 20.         19.         42.          1.         32.         35.\n 29.69911765 18.          1.         36.         29.69911765 17.\n 36.         21.         28.         23.         24.         22.\n 31.         46.         23.         28.         39.         26.\n 21.         28.         20.         34.         51.          3.\n 21.         29.69911765 29.69911765 29.69911765 33.         29.69911765\n 44.         29.69911765 34.         18.         30.         10.\n 29.69911765 21.         29.         28.         18.         29.69911765\n 28.         19.         29.69911765 32.         28.         29.69911765\n 42.         17.         50.         14.         21.         24.\n 64.         31.         45.         20.         25.         28.\n 29.69911765  4.         13.         34.          5.         52.\n 36.         29.69911765 30.         49.         29.69911765 29.\n 65.         29.69911765 50.         29.69911765 48.         34.\n 47.         48.         29.69911765 38.         29.69911765 56.\n 29.69911765  0.75       29.69911765 38.         33.         23.\n 22.         29.69911765 34.         29.         22.          2.\n  9.         29.69911765 50.         63.         25.         29.69911765\n 35.         58.         30.          9.         29.69911765 21.\n 55.         71.         21.         29.69911765 54.         29.69911765\n 25.         24.         17.         21.         29.69911765 37.\n 16.         18.         33.         29.69911765 28.         26.\n 29.         29.69911765 36.         54.         24.         47.\n 34.         29.69911765 36.         32.         30.         22.\n 29.69911765 44.         29.69911765 40.5        50.         29.69911765\n 39.         23.          2.         29.69911765 17.         29.69911765\n 30.          7.         45.         30.         29.69911765 22.\n 36.          9.         11.         32.         50.         64.\n 19.         29.69911765 33.          8.         17.         27.\n 29.69911765 22.         22.         62.         48.         29.69911765\n 39.         36.         29.69911765 40.         28.         29.69911765\n 29.69911765 24.         19.         29.         29.69911765 32.\n 62.         53.         36.         29.69911765 16.         19.\n 34.         39.         29.69911765 32.         25.         39.\n 54.         36.         29.69911765 18.         47.         60.\n 22.         29.69911765 35.         52.         47.         29.69911765\n 37.         36.         29.69911765 49.         29.69911765 49.\n 24.         29.69911765 29.69911765 44.         35.         36.\n 30.         27.         22.         40.         39.         29.69911765\n 29.69911765 29.69911765 35.         24.         34.         26.\n  4.         26.         27.         42.         20.         21.\n 21.         61.         57.         21.         26.         29.69911765\n 80.         51.         32.         29.69911765  9.         28.\n 32.         31.         41.         29.69911765 20.         24.\n  2.         29.69911765  0.75       48.         19.         56.\n 29.69911765 23.         29.69911765 18.         21.         29.69911765\n 18.         24.         29.69911765 32.         23.         58.\n 50.         40.         47.         36.         20.         32.\n 25.         29.69911765 43.         29.69911765 40.         31.\n 70.         31.         29.69911765 18.         24.5        18.\n 43.         36.         29.69911765 27.         20.         14.\n 60.         25.         14.         19.         18.         15.\n 31.          4.         29.69911765 25.         60.         52.\n 44.         29.69911765 49.         42.         18.         35.\n 18.         25.         26.         39.         45.         42.\n 22.         29.69911765 24.         29.69911765 48.         29.\n 52.         19.         38.         27.         29.69911765 33.\n  6.         17.         34.         50.         27.         20.\n 30.         29.69911765 25.         25.         29.         11.\n 29.69911765 23.         23.         28.5        48.         35.\n 29.69911765 29.69911765 29.69911765 36.         21.         24.\n 31.         70.         16.         30.         19.         31.\n  4.          6.         33.         23.         48.          0.67\n 28.         18.         34.         33.         29.69911765 41.\n 20.         36.         16.         51.         29.69911765 30.5\n 29.69911765 32.         24.         48.         57.         29.69911765\n 54.         18.         29.69911765  5.         29.69911765 43.\n 13.         17.         29.         29.69911765 25.         25.\n 18.          8.          1.         46.         29.69911765 16.\n 29.69911765 29.69911765 25.         39.         49.         31.\n 30.         30.         34.         31.         11.          0.42\n 27.         31.         39.         18.         39.         33.\n 26.         39.         35.          6.         30.5        29.69911765\n 23.         31.         43.         10.         52.         27.\n 38.         27.          2.         29.69911765 29.69911765  1.\n 29.69911765 62.         15.          0.83       29.69911765 23.\n 18.         39.         21.         29.69911765 32.         29.69911765\n 20.         16.         30.         34.5        17.         42.\n 29.69911765 35.         28.         29.69911765  4.         74.\n  9.         16.         44.         18.         45.         51.\n 24.         29.69911765 41.         21.         48.         29.69911765\n 24.         42.         27.         31.         29.69911765  4.\n 26.         47.         33.         47.         28.         15.\n 20.         19.         29.69911765 56.         25.         33.\n 22.         28.         25.         39.         27.         19.\n 29.69911765 26.         32.        ].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[118], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mimpute\u001b[39;00m \u001b[39mimport\u001b[39;00m SimpleImputer\n\u001b[0;32m      3\u001b[0m transfomer \u001b[39m=\u001b[39m SimpleImputer()\n\u001b[1;32m----> 4\u001b[0m transfomer\u001b[39m.\u001b[39;49mfit(train_data[\u001b[39m\"\u001b[39;49m\u001b[39mAge\u001b[39;49m\u001b[39m\"\u001b[39;49m])\n\u001b[0;32m      5\u001b[0m train_data \u001b[39m=\u001b[39m transfomer\u001b[39m.\u001b[39mtransform(train_data[\u001b[39m\"\u001b[39m\u001b[39mAge\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[0;32m      6\u001b[0m transfomer\u001b[39m.\u001b[39mfit(train_data[\u001b[39m\"\u001b[39m\u001b[39mSurvived\u001b[39m\u001b[39m\"\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\WSU\\anaconda3\\envs\\py311\\lib\\site-packages\\sklearn\\impute\\_base.py:390\u001b[0m, in \u001b[0;36mSimpleImputer.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    381\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mdeprecated\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    382\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    383\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThe \u001b[39m\u001b[39m'\u001b[39m\u001b[39mverbose\u001b[39m\u001b[39m'\u001b[39m\u001b[39m parameter was deprecated in version \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    384\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m1.1 and will be removed in 1.3. A warning will \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    387\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[0;32m    388\u001b[0m     )\n\u001b[1;32m--> 390\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_input(X, in_fit\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m    392\u001b[0m \u001b[39m# default fill_value is 0 for numerical input and \"missing_value\"\u001b[39;00m\n\u001b[0;32m    393\u001b[0m \u001b[39m# otherwise\u001b[39;00m\n\u001b[0;32m    394\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfill_value \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\WSU\\anaconda3\\envs\\py311\\lib\\site-packages\\sklearn\\impute\\_base.py:344\u001b[0m, in \u001b[0;36mSimpleImputer._validate_input\u001b[1;34m(self, X, in_fit)\u001b[0m\n\u001b[0;32m    342\u001b[0m         \u001b[39mraise\u001b[39;00m new_ve \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    343\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 344\u001b[0m         \u001b[39mraise\u001b[39;00m ve\n\u001b[0;32m    346\u001b[0m \u001b[39mif\u001b[39;00m in_fit:\n\u001b[0;32m    347\u001b[0m     \u001b[39m# Use the dtype seen in `fit` for non-`fit` conversion\u001b[39;00m\n\u001b[0;32m    348\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fit_dtype \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mdtype\n",
      "File \u001b[1;32mc:\\Users\\WSU\\anaconda3\\envs\\py311\\lib\\site-packages\\sklearn\\impute\\_base.py:327\u001b[0m, in \u001b[0;36mSimpleImputer._validate_input\u001b[1;34m(self, X, in_fit)\u001b[0m\n\u001b[0;32m    324\u001b[0m     force_all_finite \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    326\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 327\u001b[0m     X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(\n\u001b[0;32m    328\u001b[0m         X,\n\u001b[0;32m    329\u001b[0m         reset\u001b[39m=\u001b[39;49min_fit,\n\u001b[0;32m    330\u001b[0m         accept_sparse\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcsc\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    331\u001b[0m         dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[0;32m    332\u001b[0m         force_all_finite\u001b[39m=\u001b[39;49mforce_all_finite,\n\u001b[0;32m    333\u001b[0m         copy\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcopy,\n\u001b[0;32m    334\u001b[0m     )\n\u001b[0;32m    335\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m \u001b[39mas\u001b[39;00m ve:\n\u001b[0;32m    336\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mcould not convert\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m \u001b[39mstr\u001b[39m(ve):\n",
      "File \u001b[1;32mc:\\Users\\WSU\\anaconda3\\envs\\py311\\lib\\site-packages\\sklearn\\base.py:565\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    563\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mValidation should be done on X, y or both.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    564\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m no_val_y:\n\u001b[1;32m--> 565\u001b[0m     X \u001b[39m=\u001b[39m check_array(X, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mX\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_params)\n\u001b[0;32m    566\u001b[0m     out \u001b[39m=\u001b[39m X\n\u001b[0;32m    567\u001b[0m \u001b[39melif\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_y:\n",
      "File \u001b[1;32mc:\\Users\\WSU\\anaconda3\\envs\\py311\\lib\\site-packages\\sklearn\\utils\\validation.py:902\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    900\u001b[0m     \u001b[39m# If input is 1D raise error\u001b[39;00m\n\u001b[0;32m    901\u001b[0m     \u001b[39mif\u001b[39;00m array\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m--> 902\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    903\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mExpected 2D array, got 1D array instead:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39marray=\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    904\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mReshape your data either using array.reshape(-1, 1) if \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    905\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39myour data has a single feature or array.reshape(1, -1) \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    906\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mif it contains a single sample.\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(array)\n\u001b[0;32m    907\u001b[0m         )\n\u001b[0;32m    909\u001b[0m \u001b[39mif\u001b[39;00m dtype_numeric \u001b[39mand\u001b[39;00m array\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mkind \u001b[39min\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mUSV\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    910\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    911\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mdtype=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mnumeric\u001b[39m\u001b[39m'\u001b[39m\u001b[39m is not compatible with arrays of bytes/strings.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    912\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mConvert your data to numeric values explicitly instead.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    913\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[22.         38.         26.         35.         35.         29.69911765\n 54.          2.         27.         14.          4.         58.\n 20.         39.         14.         55.          2.         29.69911765\n 31.         29.69911765 35.         34.         15.         28.\n  8.         38.         29.69911765 19.         29.69911765 29.69911765\n 40.         29.69911765 29.69911765 66.         28.         42.\n 29.69911765 21.         18.         14.         40.         27.\n 29.69911765  3.         19.         29.69911765 29.69911765 29.69911765\n 29.69911765 18.          7.         21.         49.         29.\n 65.         29.69911765 21.         28.5         5.         11.\n 22.         38.         45.          4.         29.69911765 29.69911765\n 29.         19.         17.         26.         32.         16.\n 21.         26.         32.         25.         29.69911765 29.69911765\n  0.83       30.         22.         29.         29.69911765 28.\n 17.         33.         16.         29.69911765 23.         24.\n 29.         20.         46.         26.         59.         29.69911765\n 71.         23.         34.         34.         28.         29.69911765\n 21.         33.         37.         28.         21.         29.69911765\n 38.         29.69911765 47.         14.5        22.         20.\n 17.         21.         70.5        29.         24.          2.\n 21.         29.69911765 32.5        32.5        54.         12.\n 29.69911765 24.         29.69911765 45.         33.         20.\n 47.         29.         25.         23.         19.         37.\n 16.         24.         29.69911765 22.         24.         19.\n 18.         19.         27.          9.         36.5        42.\n 51.         22.         55.5        40.5        29.69911765 51.\n 16.         30.         29.69911765 29.69911765 44.         40.\n 26.         17.          1.          9.         29.69911765 45.\n 29.69911765 28.         61.          4.          1.         21.\n 56.         18.         29.69911765 50.         30.         36.\n 29.69911765 29.69911765  9.          1.          4.         29.69911765\n 29.69911765 45.         40.         36.         32.         19.\n 19.          3.         44.         58.         29.69911765 42.\n 29.69911765 24.         28.         29.69911765 34.         45.5\n 18.          2.         32.         26.         16.         40.\n 24.         35.         22.         30.         29.69911765 31.\n 27.         42.         32.         30.         16.         27.\n 51.         29.69911765 38.         22.         19.         20.5\n 18.         29.69911765 35.         29.         59.          5.\n 24.         29.69911765 44.          8.         19.         33.\n 29.69911765 29.69911765 29.         22.         30.         44.\n 25.         24.         37.         54.         29.69911765 29.\n 62.         30.         41.         29.         29.69911765 30.\n 35.         50.         29.69911765  3.         52.         40.\n 29.69911765 36.         16.         25.         58.         35.\n 29.69911765 25.         41.         37.         29.69911765 63.\n 45.         29.69911765  7.         35.         65.         28.\n 16.         19.         29.69911765 33.         30.         22.\n 42.         22.         26.         19.         36.         24.\n 24.         29.69911765 23.5         2.         29.69911765 50.\n 29.69911765 29.69911765 19.         29.69911765 29.69911765  0.92\n 29.69911765 17.         30.         30.         24.         18.\n 26.         28.         43.         26.         24.         54.\n 31.         40.         22.         27.         30.         22.\n 29.69911765 36.         61.         36.         31.         16.\n 29.69911765 45.5        38.         16.         29.69911765 29.69911765\n 29.         41.         45.         45.          2.         24.\n 28.         25.         36.         24.         40.         29.69911765\n  3.         42.         23.         29.69911765 15.         25.\n 29.69911765 28.         22.         38.         29.69911765 29.69911765\n 40.         29.         45.         35.         29.69911765 30.\n 60.         29.69911765 29.69911765 24.         25.         18.\n 19.         22.          3.         29.69911765 22.         27.\n 20.         19.         42.          1.         32.         35.\n 29.69911765 18.          1.         36.         29.69911765 17.\n 36.         21.         28.         23.         24.         22.\n 31.         46.         23.         28.         39.         26.\n 21.         28.         20.         34.         51.          3.\n 21.         29.69911765 29.69911765 29.69911765 33.         29.69911765\n 44.         29.69911765 34.         18.         30.         10.\n 29.69911765 21.         29.         28.         18.         29.69911765\n 28.         19.         29.69911765 32.         28.         29.69911765\n 42.         17.         50.         14.         21.         24.\n 64.         31.         45.         20.         25.         28.\n 29.69911765  4.         13.         34.          5.         52.\n 36.         29.69911765 30.         49.         29.69911765 29.\n 65.         29.69911765 50.         29.69911765 48.         34.\n 47.         48.         29.69911765 38.         29.69911765 56.\n 29.69911765  0.75       29.69911765 38.         33.         23.\n 22.         29.69911765 34.         29.         22.          2.\n  9.         29.69911765 50.         63.         25.         29.69911765\n 35.         58.         30.          9.         29.69911765 21.\n 55.         71.         21.         29.69911765 54.         29.69911765\n 25.         24.         17.         21.         29.69911765 37.\n 16.         18.         33.         29.69911765 28.         26.\n 29.         29.69911765 36.         54.         24.         47.\n 34.         29.69911765 36.         32.         30.         22.\n 29.69911765 44.         29.69911765 40.5        50.         29.69911765\n 39.         23.          2.         29.69911765 17.         29.69911765\n 30.          7.         45.         30.         29.69911765 22.\n 36.          9.         11.         32.         50.         64.\n 19.         29.69911765 33.          8.         17.         27.\n 29.69911765 22.         22.         62.         48.         29.69911765\n 39.         36.         29.69911765 40.         28.         29.69911765\n 29.69911765 24.         19.         29.         29.69911765 32.\n 62.         53.         36.         29.69911765 16.         19.\n 34.         39.         29.69911765 32.         25.         39.\n 54.         36.         29.69911765 18.         47.         60.\n 22.         29.69911765 35.         52.         47.         29.69911765\n 37.         36.         29.69911765 49.         29.69911765 49.\n 24.         29.69911765 29.69911765 44.         35.         36.\n 30.         27.         22.         40.         39.         29.69911765\n 29.69911765 29.69911765 35.         24.         34.         26.\n  4.         26.         27.         42.         20.         21.\n 21.         61.         57.         21.         26.         29.69911765\n 80.         51.         32.         29.69911765  9.         28.\n 32.         31.         41.         29.69911765 20.         24.\n  2.         29.69911765  0.75       48.         19.         56.\n 29.69911765 23.         29.69911765 18.         21.         29.69911765\n 18.         24.         29.69911765 32.         23.         58.\n 50.         40.         47.         36.         20.         32.\n 25.         29.69911765 43.         29.69911765 40.         31.\n 70.         31.         29.69911765 18.         24.5        18.\n 43.         36.         29.69911765 27.         20.         14.\n 60.         25.         14.         19.         18.         15.\n 31.          4.         29.69911765 25.         60.         52.\n 44.         29.69911765 49.         42.         18.         35.\n 18.         25.         26.         39.         45.         42.\n 22.         29.69911765 24.         29.69911765 48.         29.\n 52.         19.         38.         27.         29.69911765 33.\n  6.         17.         34.         50.         27.         20.\n 30.         29.69911765 25.         25.         29.         11.\n 29.69911765 23.         23.         28.5        48.         35.\n 29.69911765 29.69911765 29.69911765 36.         21.         24.\n 31.         70.         16.         30.         19.         31.\n  4.          6.         33.         23.         48.          0.67\n 28.         18.         34.         33.         29.69911765 41.\n 20.         36.         16.         51.         29.69911765 30.5\n 29.69911765 32.         24.         48.         57.         29.69911765\n 54.         18.         29.69911765  5.         29.69911765 43.\n 13.         17.         29.         29.69911765 25.         25.\n 18.          8.          1.         46.         29.69911765 16.\n 29.69911765 29.69911765 25.         39.         49.         31.\n 30.         30.         34.         31.         11.          0.42\n 27.         31.         39.         18.         39.         33.\n 26.         39.         35.          6.         30.5        29.69911765\n 23.         31.         43.         10.         52.         27.\n 38.         27.          2.         29.69911765 29.69911765  1.\n 29.69911765 62.         15.          0.83       29.69911765 23.\n 18.         39.         21.         29.69911765 32.         29.69911765\n 20.         16.         30.         34.5        17.         42.\n 29.69911765 35.         28.         29.69911765  4.         74.\n  9.         16.         44.         18.         45.         51.\n 24.         29.69911765 41.         21.         48.         29.69911765\n 24.         42.         27.         31.         29.69911765  4.\n 26.         47.         33.         47.         28.         15.\n 20.         19.         29.69911765 56.         25.         33.\n 22.         28.         25.         39.         27.         19.\n 29.69911765 26.         32.        ].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "transfomer = SimpleImputer()\n",
    "transfomer.fit(train_data[\"Age\"])\n",
    "train_data = transfomer.transform(train_data[\"Age\"])\n",
    "transfomer.fit(train_data[\"Survived\"])\n",
    "train_target = transfomer.transform(train_data[\"Survived\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
